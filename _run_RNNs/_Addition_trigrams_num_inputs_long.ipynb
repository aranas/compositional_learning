{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7897dc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import seaborn as sns \n",
    "from sklearn.metrics import r2_score\n",
    "import math\n",
    "import matplotlib as mpl\n",
    "from tqdm import tqdm\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "from cryptic_rnn import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15543872",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dfc30d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exp(cue_dict, j):\n",
    "\n",
    "    all_syms = list(cue_dict.keys())\n",
    "    all_input_vals = list(np.arange(2,18))\n",
    "    input_vals = random.sample(all_input_vals,num_inputs)\n",
    "    input_vals.sort() # sort values (so A is smallest)\n",
    "    # randomly select values for each input\n",
    "    for i, s in enumerate(all_syms):\n",
    "        cue_dict[s] = input_vals[i]\n",
    "    \n",
    "    trial_list = []\n",
    "    for s in range(1, len(all_syms)+1):\n",
    "        trial_list += (generate_pairs(ops, all_syms, cue_dict, s))\n",
    "    \n",
    "    primitives = generate_pos_primitives(all_syms, cue_dict)\n",
    "    balanced_prims = generate_complex_primitives(ops, all_syms, cue_dict)\n",
    "    train_trials = [trial for trial in trial_list if trial not in balanced_prims]\n",
    "    \n",
    "    basic_train = train_trials[:j]\n",
    "    trainseqs_b = basic_train + balanced_prims\n",
    "    trainseqs_p = basic_train + primitives\n",
    "    testseqs = generate_pos_trials(ops, all_syms, all_syms, cue_dict)\n",
    "    testseqs = [t for t in testseqs if t not in trainseqs_b]\n",
    "\n",
    "    # load data for primitive training\n",
    "    testseqs = change_dict(testseqs, cue_dict)\n",
    "    test_inputs = convert_seq2inputs(testseqs, num_classes=num_classes, seq_len=5)\n",
    "    testset = DataLoader(test_inputs, batch_size=batchsize, shuffle=True)\n",
    "\n",
    "    tseqs = change_dict(trainseqs_b, cue_dict)\n",
    "    train_inputs = convert_seq2inputs(tseqs, num_classes=num_classes, seq_len=5)\n",
    "    trainset_b = DataLoader(train_inputs, batch_size=batchsize, shuffle=True)\n",
    "    \n",
    "    tseqs = change_dict(trainseqs_p, cue_dict)\n",
    "    train_inputs = convert_seq2inputs(tseqs, num_classes=num_classes, seq_len=5)\n",
    "    trainset_p = DataLoader(train_inputs, batch_size=batchsize, shuffle=True)\n",
    "        \n",
    "    # run primitive training RNN\n",
    "    model_b = OneStepRNN(input_size, output_size, hidden_size, num_layers, xavier_gain)\n",
    "    model_p = copy.deepcopy(model_b)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model_b.parameters(), lr=learningRate)\n",
    "    loss1, acc1 = run_acc(model_b,optimizer,criterion, trainset_b, [trainset_b, testset], epochs, hidden_size)\n",
    "        \n",
    "    optimizer = torch.optim.Adam(model_p.parameters(), lr=learningRate)\n",
    "    loss2, acc2 = run_acc(model_p,optimizer,criterion, trainset_p, [trainset_p, testset], epochs, hidden_size)\n",
    "    \n",
    "       \n",
    "    return {'cue_dict':cue_dict,'test': testset,\n",
    "           'loss_b':loss1, 'acc_b':acc1, 'mod_b': model_b,\\\n",
    "           'loss_p':loss2, 'acc_p':acc2, 'mod_p': model_p}\n",
    "\n",
    "def run_plot(cue_dict, j):\n",
    "    \n",
    "    t1 = time.time()\n",
    "    res  = Parallel(n_jobs = -1)(delayed(run_exp)(cue_dict, j) for i in tqdm(range(num_sims)))\n",
    "    t2 = time.time()\n",
    "    print('run time: ', (t2-t1)/60)\n",
    "    \n",
    "    tests = [r['test'] for r in res]\n",
    "    cue_dicts = [r['cue_dict'] for r in res]\n",
    "    \n",
    "    losses_b = np.hstack([r['loss_b'] for r in res])\n",
    "    acc_train_b = np.array([r['acc_b'][:,0] for r in res]).T\n",
    "    acc_test_b = np.array([r['acc_b'][:,1] for r in res]).T\n",
    "    mods_b = [r['mod_b'] for r in res]\n",
    "\n",
    "    losses_p = np.hstack([r['loss_p'] for r in res])\n",
    "    acc_train_p = np.array([r['acc_p'][:,0] for r in res]).T\n",
    "    acc_test_p = np.array([r['acc_p'][:,1] for r in res]).T\n",
    "    mods_p = [r['mod_p'] for r in res]\n",
    "\n",
    "    r2_b, dfs_b, _ = predcorr(mods_b, tests, hidden_size, plot_corr =False)\n",
    "    r2_p, dfs_p, _ = predcorr(mods_p, tests, hidden_size, plot_corr = False)\n",
    "\n",
    "    print('B: ', r2_b)\n",
    "    print('P: ', r2_p)\n",
    "    \n",
    "    acc_df = pd.DataFrame({'acc_train_b': acc_train_b[-1,:], 'acc_test_b': acc_test_b[-1,:],\\\n",
    "                           'acc_train_p': acc_test_p[-1,:], 'acc_test_p': acc_test_p[-1,:]})\n",
    "    \n",
    "    return {'mods_b':mods_b, 'mods_p':mods_p, \\\n",
    "            'res':res, 'tests': tests, 'cue_dicts': cue_dicts, 'acc_df':acc_df }\n",
    "\n",
    "def input_frac_run(num_inputs, max_train_trials):\n",
    "    \n",
    "    all_syms = total_syms[:num_inputs]\n",
    "    input_vals = random.sample(all_input_vals,num_inputs)\n",
    "    # randomly select values for each input\n",
    "    cue_dict = {}\n",
    "    for i, s in enumerate(all_syms):\n",
    "        cue_dict[s] = input_vals[i]\n",
    "    \n",
    "    reses = []\n",
    "    for j in range(1, max_train_trials+1):\n",
    "        print('##################\\nnumber of train trials: ',j)      \n",
    "        res_j = run_plot(cue_dict, j)\n",
    "        reses.append(res_j)      \n",
    "    \n",
    "    return reses\n",
    "\n",
    "\n",
    "def extract_loss(res):\n",
    "    losses_b = np.hstack([r['loss_b'] for r in res])\n",
    "    losses_p = np.hstack([r['loss_p'] for r in res])\n",
    "    return {'losses_b':losses_b,'losses_p':losses_p}\n",
    "\n",
    "def extract_r2(res):\n",
    "    tests = [r['test'] for r in res]\n",
    "    mods_b = [r['mod_b'] for r in res]\n",
    "    mods_p = [r['mod_p'] for r in res]\n",
    "\n",
    "    r2_b, dfs_b, _ = predcorr(mods_b, tests, hidden_size, plot_corr =True)\n",
    "    r2_p, dfs_p, _ = predcorr(mods_p, tests, hidden_size, plot_corr = True)\n",
    "    \n",
    "def generate_pairs(op, inputs, cue_dict, shift):\n",
    "    seq = []\n",
    "    inputs1 = inputs.copy()\n",
    "    inputs2 = inputs.copy()\n",
    "    for s in range(shift):\n",
    "        inputs2.append(inputs2.pop(0))\n",
    "    for i in range(len(inputs1)):\n",
    "        trial = [(op, inputs1[i]), (op, inputs2[i]), '=']\n",
    "        trial.append(calculate_output(trial, cue_dict))\n",
    "        seq.append(trial)\n",
    "    return seq\n",
    "\n",
    "\n",
    "def extract_r2(res):\n",
    "    \"\"\" calculates mean and std R^2 for model predictions-ground truth correlation for model set of \n",
    "        each training regime\n",
    "        Args: results dictionary\n",
    "        Returns, mean R^2 and std for balanced and primitive regime\"\"\"\n",
    "    tests = res['tests']\n",
    "    mods_b = res['mods_b']\n",
    "    mods_p = res['mods_p']\n",
    "    r2_b, sterr_b = get_r2s(mods_b, tests, hidden_size)\n",
    "    r2_p, sterr_p = get_r2s(mods_p, tests, hidden_size)\n",
    "    \n",
    "    return [r2_b, r2_p, sterr_b, sterr_p]\n",
    "    \n",
    "def get_r2s(mods, tests, hidden_size=20):\n",
    "    \"\"\" calculates mean R^2 and std for list of models and test sequences \"\"\"\n",
    "    N = len(mods)\n",
    "    r2s = []\n",
    "    for i in range(len(mods)):\n",
    "        df = test_preds(mods[i], [tests[i]], hidden_size)\n",
    "        r2s.append(r2_score(df['pred'], df['label'])) # individual model r2 score\n",
    "    r2_mean = np.mean(r2s)\n",
    "    r2_sterr = np.std(r2s)/math.sqrt(N)\n",
    "    \n",
    "    return r2_mean, r2_sterr\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "56bf5f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plotting\n",
    "SMALL_SIZE = 12\n",
    "MEDIUM_SIZE = 14\n",
    "BIGGER_SIZE = 18\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce70c94",
   "metadata": {},
   "source": [
    "## RNN params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ece207bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "num_classes = 22\n",
    "batchsize=1\n",
    "\n",
    "# RNN specs\n",
    "input_size = num_classes\n",
    "output_size = 1\n",
    "num_layers = 1\n",
    "hidden_size = 20\n",
    "learningRate = 0.005\n",
    "xavier_gain = 0.0001\n",
    "\n",
    "## running params\n",
    "epochs = 1000\n",
    "num_sims = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7620e8e9",
   "metadata": {},
   "source": [
    "## Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84a09888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cue_dict  {'A': 14, 'B': 10, 'C': 6, 'D': 7}\n"
     ]
    }
   ],
   "source": [
    "ops = '+'\n",
    "\n",
    "num_inputs = 4\n",
    "total_syms = ['A','B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P']\n",
    "all_syms = total_syms[:num_inputs]\n",
    "all_input_vals = list(np.arange(2,18))\n",
    "input_vals = random.sample(all_input_vals,num_inputs)\n",
    "# randomly select values for each input\n",
    "cue_dict = {}\n",
    "for i, s in enumerate(all_syms):\n",
    "    cue_dict[s] = input_vals[i]  \n",
    "print('cue_dict ',cue_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fe535933",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sims= 200\n",
    "epochs = 1000\n",
    "res = input_frac_run(4, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d8517079",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = np.empty((0,4))\n",
    "for i, res_set in enumerate(res):\n",
    "    set_vals = np.array(extract_r2(res_set)).reshape(-1,4)\n",
    "    vals = np.vstack([vals, set_vals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94be7b24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vals' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6y/z1h4y1t94jvb186qws4p3qq40000gn/T/ipykernel_29702/2999502989.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'#00A7E1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'#F17720'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mxpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mNn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vals' is not defined"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "labels = ['Balanced','Primitives']\n",
    "colors = ['#00A7E1', '#F17720']\n",
    "\n",
    "xpos = np.arange(1, vals.shape[0]+1)\n",
    "Nn = int(vals.shape[1]/2)\n",
    "for j in range(Nn):\n",
    "    plt.plot(xpos, vals[:,j], label = labels[j], color=colors[j])\n",
    "    plt.fill_between(xpos, vals[:,j] + vals[:,j+Nn], vals[:,j] - vals[:,j+Nn], color=colors[j], alpha=0.2)\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel('Number of base training trials')\n",
    "plt.ylabel('$R^2$')\n",
    "plt.suptitle('$R^2$ score against number of training trails')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7f2caa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "savedir = '../results/fraction_inputs/4_inputs'\n",
    "with open(savedir, 'wb') as f:\n",
    "    pickle.dump(res, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "49e8a7d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mods_b', 'mods_p', 'res', 'tests', 'cue_dicts', 'acc_df'])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f5c04ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 1\n",
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dd5a595b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0]['acc_df']['acc_train_b'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b8d7d57e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1776923076923077"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0]['acc_df']['acc_train_p'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df7006e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
