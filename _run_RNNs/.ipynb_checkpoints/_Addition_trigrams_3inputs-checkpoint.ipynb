{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7897dc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import seaborn as sns \n",
    "from sklearn.metrics import r2_score\n",
    "import math\n",
    "import matplotlib as mpl\n",
    "from tqdm import tqdm\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "from cryptic_rnn import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15543872",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dfc30d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exp(trainseqs_old ,trainseqs_old_b, trainseqs_old_p, trainseqs_old_bp, testseqs_old, cue_dict):\n",
    "\n",
    "    all_syms = list(cue_dict.keys())\n",
    "    all_input_vals = list(np.arange(2,18))\n",
    "    input_vals = random.sample(all_input_vals,num_inputs)\n",
    "    input_vals.sort() # sort values (so A is smallest)\n",
    "    # randomly select values for each input\n",
    "    for i, s in enumerate(all_syms):\n",
    "        cue_dict[s] = input_vals[i]\n",
    "    \n",
    "    # load data for primitive training\n",
    "    trainseqs = change_dict(trainseqs_old, cue_dict)\n",
    "    train_inputs = convert_seq2inputs(trainseqs, num_classes=num_classes, seq_len=5)\n",
    "    trainset = DataLoader(train_inputs, batch_size=batchsize, shuffle=True)\n",
    "\n",
    "    trainseqs = change_dict(trainseqs_old_b, cue_dict)\n",
    "    train_inputs = convert_seq2inputs(trainseqs, num_classes=num_classes, seq_len=5)\n",
    "    trainset_b = DataLoader(train_inputs, batch_size=batchsize, shuffle=True)\n",
    "    \n",
    "    trainseqs = change_dict(trainseqs_old_p, cue_dict)\n",
    "    train_inputs = convert_seq2inputs(trainseqs, num_classes=num_classes, seq_len=5)\n",
    "    trainset_p = DataLoader(train_inputs, batch_size=batchsize, shuffle=True)\n",
    "    \n",
    "    trainseqs = change_dict(trainseqs_old_bp, cue_dict)\n",
    "    train_inputs = convert_seq2inputs(trainseqs, num_classes=num_classes, seq_len=5)\n",
    "    trainset_bp = DataLoader(train_inputs, batch_size=batchsize, shuffle=True)\n",
    "        \n",
    "    testseqs = change_dict(testseqs_old, cue_dict)\n",
    "    test_inputs = convert_seq2inputs(testseqs, num_classes=num_classes, seq_len=5)\n",
    "    testset = DataLoader(test_inputs, batch_size=batchsize, shuffle=True)\n",
    "\n",
    "    # run primitive training RNN\n",
    "    model = OneStepRNN(input_size, output_size, hidden_size, num_layers, xavier_gain)\n",
    "    model_b = copy.deepcopy(model)\n",
    "    model_p = copy.deepcopy(model)\n",
    "    model_bp = copy.deepcopy(model)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learningRate)\n",
    "    loss1, acc1 = run_acc(model,optimizer,criterion, trainset, [trainset, testset], epochs, hidden_size)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model_b.parameters(), lr=learningRate)\n",
    "    loss2, acc2 = run_acc(model_b,optimizer,criterion, trainset_b, [trainset_b, testset], epochs, hidden_size)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model_p.parameters(), lr=learningRate)\n",
    "    loss3, acc3 = run_acc(model_p,optimizer,criterion, trainset_p, [trainset_p, testset], epochs, hidden_size)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model_bp.parameters(), lr=learningRate)\n",
    "    loss4, acc4 = run_acc(model_bp,optimizer,criterion, trainset_bp, [trainset_bp, testset], epochs, hidden_size)\n",
    "       \n",
    "    return {'cue_dict':cue_dict, 'loss':loss1, 'acc':acc1, 'mod': model, 'test': testset,\n",
    "           'loss_b':loss2, 'acc_b':acc2, 'mod_b': model_b,\\\n",
    "           'loss_p':loss3, 'acc_p':acc3, 'mod_p': model_p,\\\n",
    "           'loss_bp':loss4, 'acc_bp':acc4, 'mod_bp': model_bp}\n",
    "\n",
    "def run_plot(trainseqs, trainseqs_b, trainseqs_p, trainseqs_bp, testseqs, cue_dict):\n",
    "    t1 = time.time()\n",
    "    res  = Parallel(n_jobs = -1)(delayed(run_exp)(trainseqs, trainseqs_b, trainseqs_p, trainseqs_bp,testseqs, cue_dict) for i in tqdm(range(num_sims)))\n",
    "    t2 = time.time()\n",
    "    print('run time: ', (t2-t1)/60)\n",
    "    \n",
    "    tests = [r['test'] for r in res]\n",
    "    cue_dicts = [r['cue_dict'] for r in res]\n",
    "    \n",
    "    losses = np.hstack([r['loss'] for r in res])\n",
    "    acc_train = np.array([r['acc'][:,0] for r in res]).T\n",
    "    acc_test = np.array([r['acc'][:,1] for r in res]).T\n",
    "    mods = [r['mod'] for r in res]\n",
    "    \n",
    "    losses_b = np.hstack([r['loss_b'] for r in res])\n",
    "    acc_train_b = np.array([r['acc_b'][:,0] for r in res]).T\n",
    "    acc_test_b = np.array([r['acc_b'][:,1] for r in res]).T\n",
    "    mods_b = [r['mod_b'] for r in res]\n",
    "\n",
    "    losses_p = np.hstack([r['loss_p'] for r in res])\n",
    "    acc_train_p = np.array([r['acc_p'][:,0] for r in res]).T\n",
    "    acc_test_p = np.array([r['acc_p'][:,1] for r in res]).T\n",
    "    mods_p = [r['mod_p'] for r in res]\n",
    "    \n",
    "    losses_bp = np.hstack([r['loss_bp'] for r in res])\n",
    "    acc_train_bp = np.array([r['acc_bp'][:,0] for r in res]).T\n",
    "    acc_test_bp = np.array([r['acc_bp'][:,1] for r in res]).T\n",
    "    mods_bp = [r['mod_bp'] for r in res]\n",
    "    \n",
    "    plotNNs([losses], [acc_train, acc_test], \\\n",
    "            ['train', 'test'], colors = ['green', 'orange'], title = 'no primitives', shift = 0)\n",
    "    plotNNs([losses_b], [acc_train_b, acc_test_b], \\\n",
    "            ['train', 'test'], colors = ['green', 'orange'], title = 'balanced -no primitives', shift = 0)\n",
    "    plotNNs([losses_p], [acc_train_p, acc_test_p], \\\n",
    "            ['train', 'test'], colors = ['green', 'orange'], title = 'with primitives', shift = 0)\n",
    "    plotNNs([losses_bp], [acc_train_bp, acc_test_bp], \\\n",
    "            ['train', 'test'], colors = ['green', 'orange'], title = 'balanced - with primitives', shift = 0)\n",
    "\n",
    "    plt.figure()\n",
    "    r2, dfs, _ = predcorr(mods, tests, hidden_size, plot_corr = True)\n",
    "    plt.title('without primitives; r^2 = '+ str(round(r2, 3)))\n",
    "    plt.figure()\n",
    "    r2_b, dfs_b, _ = predcorr(mods_b, tests, hidden_size, plot_corr =True)\n",
    "    plt.title('balanced-without primitives; r^2 = '+ str(round(r2_b, 3)))\n",
    "    plt.figure()\n",
    "    r2_p, dfs_p, _ = predcorr(mods_p, tests, hidden_size, plot_corr = True)\n",
    "    plt.title('with primitives; r^2 = '+ str(round(r2_p, 3)))\n",
    "    plt.figure()\n",
    "    r2_bp, dfs_bp, _ = predcorr(mods_bp, tests, hidden_size, plot_corr =True)\n",
    "    plt.title('balanced-with primitives; r^2 = '+ str(round(r2_bp, 3)))\n",
    "\n",
    "    acc_df = pd.DataFrame({'acc_train': acc_train[-1,:], 'acc_train_b': acc_train_b[-1,:],\\\n",
    "                           'acc_train_p': acc_train_p[-1,:], 'acc_train_bp': acc_train_bp[-1,:],\\\n",
    "                           'acc_test': acc_test[-1,:], 'acc_test_b': acc_test_b[-1,:],\\\n",
    "                           'acc_test_p': acc_test_p[-1,:], 'acc_test_bp': acc_test_bp[-1,:]})\n",
    "    \n",
    "    return {'mods':mods, 'mods_b':mods_b, 'mods_p':mods_p, 'mods_bp':mods_bp, \\\n",
    "            'res':res, 'tests': tests, 'cue_dicts': cue_dicts, 'acc_df':acc_df }\n",
    "\n",
    "def extract_loss(res):\n",
    "    losses = np.hstack([r['loss'] for r in res])\n",
    "    losses_b = np.hstack([r['loss_b'] for r in res])\n",
    "    losses_p = np.hstack([r['loss_p'] for r in res])\n",
    "    losses_bp = np.hstack([r['loss_bp'] for r in res])\n",
    "    return {'losses':losses, 'losses_b':losses_b,'losses_p':losses_p, 'losses_bp':losses_bp}\n",
    "    \n",
    "def plot_traincurve(res):\n",
    "    \n",
    "    losses = np.hstack([r['loss'] for r in res])\n",
    "    acc_train = np.array([r['acc'][:,0] for r in res]).T\n",
    "    acc_test = np.array([r['acc'][:,1] for r in res]).T\n",
    "    mods = [r['mod'] for r in res]\n",
    "    \n",
    "    losses_b = np.hstack([r['loss_b'] for r in res])\n",
    "    acc_train_b = np.array([r['acc_b'][:,0] for r in res]).T\n",
    "    acc_test_b = np.array([r['acc_b'][:,1] for r in res]).T\n",
    "    mods_b = [r['mod_b'] for r in res]\n",
    "\n",
    "    losses_p = np.hstack([r['loss_p'] for r in res])\n",
    "    acc_train_p = np.array([r['acc_p'][:,0] for r in res]).T\n",
    "    acc_test_p = np.array([r['acc_p'][:,1] for r in res]).T\n",
    "    mods_p = [r['mod_p'] for r in res]\n",
    "    \n",
    "    losses_bp = np.hstack([r['loss_bp'] for r in res])\n",
    "    acc_train_bp = np.array([r['acc_bp'][:,0] for r in res]).T\n",
    "    acc_test_bp = np.array([r['acc_bp'][:,1] for r in res]).T\n",
    "    mods_bp = [r['mod_bp'] for r in res]\n",
    "    \n",
    "    plotNNs([losses], [acc_train, acc_test], \\\n",
    "            ['train', 'test'], colors = ['green', 'orange'], title = 'no primitives', shift = 0)\n",
    "    plotNNs([losses_b], [acc_train_b, acc_test_b], \\\n",
    "            ['train', 'test'], colors = ['green', 'orange'], title = 'balanced -no primitives', shift = 0)\n",
    "    plotNNs([losses_p], [acc_train_p, acc_test_p], \\\n",
    "            ['train', 'test'], colors = ['green', 'orange'], title = 'with primitives', shift = 0)\n",
    "    plotNNs([losses_bp], [acc_train_bp, acc_test_bp], \\\n",
    "            ['train', 'test'], colors = ['green', 'orange'], title = 'balanced - with primitives', shift = 0)\n",
    "\n",
    "def plot_r2(res):\n",
    "    \n",
    "    tests = [r['test'] for r in res]\n",
    "    cue_dicts = [r['cue_dict'] for r in res]\n",
    "\n",
    "    mods = [r['mod'] for r in res]\n",
    "    mods_b = [r['mod_b'] for r in res]\n",
    "    mods_p = [r['mod_p'] for r in res]\n",
    "    mods_bp = [r['mod_bp'] for r in res]\n",
    "    \n",
    "    plt.figure()\n",
    "    r2, dfs, _ = predcorr(mods, tests, hidden_size, plot_corr = True)\n",
    "    plt.title('without primitives; r^2 = '+ str(r2))\n",
    "    plt.figure()\n",
    "    r2_b, dfs_b, _ = predcorr(mods_b, tests, hidden_size, plot_corr =True)\n",
    "    plt.title('balanced-without primitives; r^2 = '+ str(r2_b))\n",
    "    plt.figure()\n",
    "    r2_p, dfs_p, _ = predcorr(mods_p, tests, hidden_size, plot_corr = True)\n",
    "    plt.title('with primitives; r^2 = '+ str(r2_p))\n",
    "    plt.figure()\n",
    "    r2_bp, dfs_bp, _ = predcorr(mods_bp, tests, hidden_size, plot_corr =True)\n",
    "    plt.title('balanced-with primitives; r^2 = '+ str(r2_bp))\n",
    "    \n",
    "\n",
    "    \n",
    "def calculate_RDMs(res, testseq, subset = 'bp'):\n",
    "    \n",
    "    acc_df = res['acc_df']\n",
    "    if subset == 'bp':\n",
    "        all_acc_mods = acc_df[(acc_df['acc_train'] == 1) & (acc_df['acc_train_b'] == 1)&\\\n",
    "                              (acc_df['acc_train_bp'] == 1) & (acc_df['acc_train_p'] == 1)].index\n",
    "\n",
    "    elif subset == 'ft':\n",
    "        all_acc_mods = acc_df[(acc_df['acc_train'] == 1) & (acc_df['acc_train_p'] == 1)].index\n",
    "    elif subset == 'all':\n",
    "        all_acc_mods = acc_df.index\n",
    "    print('no. 100% trained RNNs: ', len(all_acc_mods))\n",
    "    mod_list = all_acc_mods # choose subset of rnns \n",
    "\n",
    "    rdms = [[] for _ in range(4)] # initialise empty lists/arrays\n",
    "    rdms_p = [[] for _ in range(4)]\n",
    "    rdms_b = [[] for _ in range(4)] # initialise empty lists/arrays\n",
    "    rdms_bp = [[] for _ in range(4)]\n",
    "    # extracts res1ults from dictionary\n",
    "    mods = res1['mods']\n",
    "    mods_p = res1['mods_p']\n",
    "    mods_b = res1['mods_b']\n",
    "    mods_bp = res1['mods_bp']\n",
    "\n",
    "    cue_dicts = res1['cue_dicts']\n",
    "    ft_cue_dicts = [cue_dicts[j] for j in mod_list]\n",
    "\n",
    "    for ind, m in enumerate(mod_list): # for each model \n",
    "\n",
    "        testseqs = change_dict(testseq, cue_dicts[m])\n",
    "        test_inputs = convert_seq2inputs(testseqs, num_classes=num_classes, seq_len=5)\n",
    "        testset = DataLoader(test_inputs, batch_size=batchsize, shuffle=False)\n",
    "\n",
    "        # get activations for control model\n",
    "        hiddens, trials = get_reps(mods[m], [testset], hidden_size)\n",
    "        for h in range(4): \n",
    "            hid_vals = np.array([hid[h+1,:] for hid in hiddens]) # combine activations from each trial for the time step\n",
    "            rep_mat = euclidean_distances(hid_vals) # calculate euclidean distance matrix between trials\n",
    "            rdms[h].append(rep_mat)\n",
    "\n",
    "        # get activations for primitive trained model\n",
    "        hiddens_p, trials = get_reps(mods_p[m], [testset], hidden_size)    \n",
    "        for h in range(4):\n",
    "            hid_vals = np.array([hid[h+1,:] for hid in hiddens_p])\n",
    "            rep_mat = euclidean_distances(hid_vals)\n",
    "            rdms_p[h].append(rep_mat)\n",
    "\n",
    "        if subset == 'bp':\n",
    "\n",
    "            # get activations for control model\n",
    "            hiddens_b, trials = get_reps(mods_b[m], [testset], hidden_size)\n",
    "            for h in range(4): \n",
    "                hid_vals = np.array([hid[h+1,:] for hid in hiddens_b]) # combine activations from each trial for the time step\n",
    "                rep_mat = euclidean_distances(hid_vals) # calculate euclidean distance matrix between trials\n",
    "                rdms_b[h].append(rep_mat)\n",
    "\n",
    "            # get activations for primitive trained model\n",
    "            hiddens_bp, trials = get_reps(mods_p[m], [testset], hidden_size)    \n",
    "            for h in range(4):\n",
    "                hid_vals = np.array([hid[h+1,:] for hid in hiddens_bp])\n",
    "                rep_mat = euclidean_distances(hid_vals)\n",
    "                rdms_bp[h].append(rep_mat)\n",
    "\n",
    "            \n",
    "    return {'rdms': rdms, 'rdms_p': rdms_p, 'rdms_b': rdms_b, 'rdms_bp': rdms_bp, 'ft_cue_dicts': ft_cue_dicts}\n",
    "\n",
    "def MDS_plot(matlist, testseqs, trainseqs, title = ''):\n",
    "    \n",
    "    valset = [t for t in testseqs if t not in trainseqs]\n",
    "    valset_idx = [testseqs.index(val) for val in valset]\n",
    "    \n",
    "    colors2 = ['green', 'blue', 'orange', 'red']*4\n",
    "    colors1 = ['green']*4 + ['blue']*4 + ['orange']*4 + [ 'red']*4\n",
    "    legend_elements = [Line2D([0], [0], marker='o', color='w', markerfacecolor='green', markersize=5, label='A + _'),\n",
    "                       Line2D([0], [0], marker='o', color='w', markerfacecolor='blue', markersize=5, label='B + _'), \n",
    "                       Line2D([0], [0], marker='o', color='w', markerfacecolor='orange', markersize=5, label='C + _'),\n",
    "                       Line2D([0], [0], marker='o', color='w', markerfacecolor='red', markersize=5, label='D + _'),\n",
    "                       Line2D([0], [0], marker='o', color='w', markeredgecolor = 'green', markerfacecolor='none', markersize=10, label=' _ + A'),\n",
    "                       Line2D([0], [0], marker='o', color='w', markeredgecolor = 'blue',markerfacecolor='none', markersize=10, label=' _ + B'), \n",
    "                       Line2D([0], [0], marker='o', color='w', markeredgecolor = 'orange',markerfacecolor='none', markersize=10, label=' _ + C'),\n",
    "                       Line2D([0], [0], marker='o', color='w', markeredgecolor = 'red',markerfacecolor='none', markersize=10, label=' _ + D')]\n",
    "    \n",
    "    \n",
    "    plt.rcParams['figure.figsize'] = 6, 6\n",
    "    fig, axs = plt.subplots(2,2)\n",
    "\n",
    "    for j, dist in enumerate(matlist):\n",
    "        mds = MDS(dissimilarity='precomputed',random_state=0, n_components=2)\n",
    "        X_transform = mds.fit_transform(dist)\n",
    "        ax = axs[math.floor(j/2), j%2]\n",
    "        ax.title.set_text('step: '+str(j+1))\n",
    "        for i in range(len(testseqs)):\n",
    "            if i in valset_idx:\n",
    "                alph = 1\n",
    "            else:\n",
    "                alph = 0.2\n",
    "            ax.scatter(X_transform[i,0], X_transform[i,1], color = colors1[i], alpha = alph)\n",
    "            ax.scatter(X_transform[i,0], X_transform[i,1], s=100, facecolors='none', edgecolors=colors2[i], alpha = alph)\n",
    "\n",
    "    plt.suptitle('2D-MDS'+title)\n",
    "    fig.legend(handles=legend_elements,  loc='center left', bbox_to_anchor=(1, 0.5)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce70c94",
   "metadata": {},
   "source": [
    "## RNN params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ece207bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "num_classes = 22\n",
    "batchsize=1\n",
    "\n",
    "# RNN specs\n",
    "input_size = num_classes\n",
    "output_size = 1\n",
    "num_layers = 1\n",
    "hidden_size = 20\n",
    "learningRate = 0.005\n",
    "xavier_gain = 0.0001\n",
    "\n",
    "## running params\n",
    "epochs = 1500\n",
    "num_sims = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7620e8e9",
   "metadata": {},
   "source": [
    "## Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84a09888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cue_dict  {'A': 9, 'B': 2, 'C': 13, 'D': 17}\n",
      "primitives  [[('+', 'A'), '=', 9], [('+', 'B'), '=', 2], [('+', 'C'), '=', 13], [('+', 'D'), '=', 17]]\n",
      "trainseqs  [[('+', 'A'), ('+', 'B'), '=', 11], [('+', 'B'), ('+', 'C'), '=', 15], [('+', 'C'), ('+', 'A'), '=', 22]]\n",
      "trainseqs_b  [[('+', 'A'), ('+', 'B'), '=', 11], [('+', 'B'), ('+', 'C'), '=', 15], [('+', 'C'), ('+', 'A'), '=', 22], ['A', ('+', 'C'), '=', 22], ['B', ('+', 'D'), '=', 19]]\n",
      "trainseqs_p  [[('+', 'A'), ('+', 'B'), '=', 11], [('+', 'B'), ('+', 'C'), '=', 15], [('+', 'C'), ('+', 'A'), '=', 22], [('+', 'A'), '=', 9], [('+', 'B'), '=', 2], [('+', 'C'), '=', 13], [('+', 'D'), '=', 17]]\n",
      "trainseqs_bp  [[('+', 'A'), ('+', 'B'), '=', 11], [('+', 'B'), ('+', 'C'), '=', 15], [('+', 'C'), ('+', 'A'), '=', 22], ['A', ('+', 'C'), '=', 22], ['B', ('+', 'D'), '=', 19], [('+', 'A'), '=', 9], [('+', 'B'), '=', 2], [('+', 'C'), '=', 13], [('+', 'D'), '=', 17]]\n",
      "testseqs  [[('+', 'A'), ('+', 'A'), '=', 18], [('+', 'A'), ('+', 'C'), '=', 22], [('+', 'A'), ('+', 'D'), '=', 26], [('+', 'B'), ('+', 'A'), '=', 11], [('+', 'B'), ('+', 'B'), '=', 4], [('+', 'B'), ('+', 'D'), '=', 19], [('+', 'C'), ('+', 'B'), '=', 15], [('+', 'C'), ('+', 'C'), '=', 26], [('+', 'C'), ('+', 'D'), '=', 30], [('+', 'D'), ('+', 'A'), '=', 26], [('+', 'D'), ('+', 'B'), '=', 19], [('+', 'D'), ('+', 'C'), '=', 30], [('+', 'D'), ('+', 'D'), '=', 34]]\n"
     ]
    }
   ],
   "source": [
    "ops = '+'\n",
    "\n",
    "num_inputs = 4\n",
    "total_syms = ['A','B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P']\n",
    "all_syms = total_syms[:num_inputs]\n",
    "all_input_vals = list(np.arange(2,18))\n",
    "input_vals = random.sample(all_input_vals,num_inputs)\n",
    "# randomly select values for each input\n",
    "cue_dict = {}\n",
    "for i, s in enumerate(all_syms):\n",
    "    cue_dict[s] = input_vals[i]\n",
    "    \n",
    "print('cue_dict ',cue_dict)\n",
    "primitives = generate_pos_primitives(all_syms, cue_dict)\n",
    "print('primitives ',primitives)\n",
    "\n",
    "trainseqs = generate_pos_other(ops, all_syms[:-1], cue_dict)\n",
    "trainseqs_b = generate_pos_other(ops, all_syms[:-1], cue_dict) + generate_balanced_primitives(ops, all_syms, cue_dict)\n",
    "trainseqs_p = trainseqs + primitives\n",
    "trainseqs_bp = trainseqs_b + primitives\n",
    "\n",
    "print('trainseqs ',trainseqs)\n",
    "print('trainseqs_b ',trainseqs_b)\n",
    "print('trainseqs_p ',trainseqs_p)\n",
    "print('trainseqs_bp ',trainseqs_bp)\n",
    "\n",
    "testseqs = generate_pos_trials(ops, all_syms, all_syms, cue_dict)\n",
    "testseqs = [seq for seq in testseqs if seq not in trainseqs_b]\n",
    "\n",
    "print('testseqs ', testseqs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55be3ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████                      | 8/16 [00:20<00:00, 49.38it/s]"
     ]
    }
   ],
   "source": [
    "# run\n",
    "res1 = run_plot(trainseqs, trainseqs_b, trainseqs_p, trainseqs_bp, testseqs, cue_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f12ae08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
