{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ee739f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import seaborn as sns \n",
    "from sklearn.metrics import r2_score\n",
    "import math\n",
    "import matplotlib as mpl\n",
    "\n",
    "from cryptic_rnn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1db8340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exp(trainseqs_old, trainseqs_old_p, testseqs_old, cue_dict, num_inputs):\n",
    "    \"\"\" assigns integers to symbols and trains RNN on sequence - evaluating on test set on each trial\"\"\"\n",
    "    # assigning value to symbol and calculating trial outputs\n",
    "    all_syms = list(cue_dict.keys())\n",
    "    all_input_vals = list(np.arange(2,18))\n",
    "    input_vals = random.sample(all_input_vals,num_inputs)\n",
    "    input_vals.sort() # sort values (so A is smallest)\n",
    "    # randomly select values for each input\n",
    "    for i, s in enumerate(all_syms):\n",
    "        cue_dict[s] = input_vals[i]\n",
    "    \n",
    "    # load train and test trials\n",
    "    trainseqs = change_dict(trainseqs_old, cue_dict)\n",
    "    train_inputs = convert_seq2inputs(trainseqs, num_classes=num_classes, seq_len=5)\n",
    "    trainset = DataLoader(train_inputs, batch_size=batchsize, shuffle=True)\n",
    "\n",
    "    trainseqs = change_dict(trainseqs_old_p, cue_dict)\n",
    "    train_inputs = convert_seq2inputs(trainseqs, num_classes=num_classes, seq_len=5)\n",
    "    trainset_p = DataLoader(train_inputs, batch_size=batchsize, shuffle=True)\n",
    "    \n",
    "    testseqs = change_dict(testseqs_old, cue_dict)\n",
    "    test_inputs = convert_seq2inputs(testseqs, num_classes=num_classes, seq_len=5)\n",
    "    testset = DataLoader(test_inputs, batch_size=batchsize, shuffle=True)\n",
    "\n",
    "    # run primitive training RNN\n",
    "    model = OneStepRNN(input_size, output_size, hidden_size, num_layers, xavier_gain)\n",
    "    model_p = copy.deepcopy(model)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learningRate)\n",
    "    loss1, acc1 = run_acc(model,optimizer,criterion, trainset, [trainset, testset], epochs, hidden_size)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model_p.parameters(), lr=learningRate)\n",
    "    loss2, acc2 = run_acc(model_p,optimizer,criterion, trainset_p, [trainset_p, testset], epochs, hidden_size)\n",
    "       \n",
    "    return {'cue_dict':cue_dict, 'loss':loss1, 'acc':acc1, 'mod': model, 'test': testset,\n",
    "           'loss_p':loss2, 'acc_p':acc2, 'mod_p': model_p}\n",
    "\n",
    "def collect_accs(trainseqs, trainseqs_p, testseqs, cue_dict, num_inputs):\n",
    "    \"\"\" trains RNNs in parallel and collects r^2 and acc vals\"\"\"\n",
    "    t1 = time.time()\n",
    "    res  = Parallel(n_jobs = -1)(delayed(run_exp)(trainseqs, trainseqs_p, testseqs, cue_dict, num_inputs) for i in range(num_sims))\n",
    "    t2 = time.time()\n",
    "    print('run time: ', (t2-t1)/60)\n",
    "\n",
    "    tests = [r['test'] for r in res]\n",
    "    cue_dicts = [r['cue_dict'] for r in res]\n",
    "    \n",
    "    mods = [r['mod'] for r in res]\n",
    "    acc_train_list = [r['acc'][:,0] for r in res]\n",
    "    acc_test_list = [r['acc'][:,1] for r in res]\n",
    "    acc_train = np.array(acc_train_list).T\n",
    "    acc_test = np.array(acc_test_list).T\n",
    "\n",
    "    mods_p = [r['mod_p'] for r in res]\n",
    "    acc_train_list_p = [r['acc_p'][:,0] for r in res]\n",
    "    acc_test_list_p = [r['acc_p'][:,1] for r in res]\n",
    "    acc_train_p = np.array(acc_train_list_p).T\n",
    "    acc_test_p = np.array(acc_test_list_p).T\n",
    "       \n",
    "    acc_df = pd.DataFrame({'acc_train': acc_train[-1,:], 'acc_train_p': acc_train_p[-1,:],\\\n",
    "                          'acc_test': acc_test[-1,:], 'acc_test_p': acc_test_p[-1,:]})\n",
    "    \n",
    "    # fully trained\n",
    "    fully_trained = acc_df[(acc_df['acc_train'] == 1)&(acc_df['acc_train_p'] == 1)]\n",
    "    fully_trained_idx = fully_trained.index\n",
    "    ft_mods = [mods[i] for i in fully_trained_idx]\n",
    "    print('fully trained models: ',len(ft_mods))\n",
    "    \n",
    "    if len(ft_mods) > 0:\n",
    "        \n",
    "        ft_tests = [tests[i] for i in fully_trained_idx]\n",
    "        ft_mods_p = [mods_p[i] for i in fully_trained_idx]\n",
    "\n",
    "        ft_tests_acc = np.array([acc_test_list[i] for i in fully_trained_idx]).T\n",
    "        ft_train_acc = np.array([acc_train_list[i] for i in fully_trained_idx]).T\n",
    "        final_acc = np.mean(ft_tests_acc[-1,:])\n",
    "        final_acc_std = np.std(ft_tests_acc[-1,:])\n",
    "              \n",
    "        ft_tests_acc_p = np.array([acc_test_list_p[i] for i in fully_trained_idx]).T\n",
    "        ft_train_acc_p = np.array([acc_train_list_p[i] for i in fully_trained_idx]).T\n",
    "        final_acc_p = np.mean(ft_tests_acc_p[-1,:])\n",
    "        final_acc_std_p = np.std(ft_tests_acc_p[-1,:])\n",
    "        \n",
    "        r2, dfs, alldfs = predcorr(ft_mods, ft_tests, hidden_size, plot_corr = False)\n",
    "        r2_p, dfs_p, alldfs = predcorr(ft_mods_p, ft_tests, hidden_size, plot_corr =False)\n",
    "        \n",
    "        print('no prims R^2: ', r2, '; acc = ', final_acc)\n",
    "        print('with prims R^2: ', r2_p, '; acc = ', final_acc_p)\n",
    "\n",
    "    else:\n",
    "        r2, dfs, final_acc = 0, 0, 0\n",
    "        r2_p, dfs_p, final_acc_p = 0, 0, 0\n",
    "        \n",
    "    return {'res':res, 'mods':mods, 'mods_p':mods_p, 'tests': tests, 'cue_dicts': cue_dicts, 'acc_df':acc_df,\\\n",
    "           'dfs':dfs, 'dfs_p':dfs_p, 'r2':r2, 'r2_p':r2_p, 'final_acc':final_acc, 'final_acc_p': final_acc_p,\\\n",
    "           'final_acc_std':final_acc, 'final_acc_std_p': final_acc_p}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bc6c104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "num_classes = 22\n",
    "batchsize=1\n",
    "\n",
    "# RNN specs\n",
    "input_size = num_classes\n",
    "output_size = 1\n",
    "num_layers = 1\n",
    "hidden_size = 20\n",
    "learningRate = 0.005\n",
    "\n",
    "## running params\n",
    "epochs = 12\n",
    "num_sims = 8\n",
    "\n",
    "# \n",
    "xavier_gain = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dec2217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 16, 'B': 3, 'C': 4, 'D': 6}\n",
      "[['A', '=', 16], ['B', '=', 3], ['C', '=', 4], ['D', '=', 6]]\n",
      "[[('+', 'A'), '=', 16], [('+', 'B'), '=', 3], [('+', 'C'), '=', 4], [('+', 'D'), '=', 6]]\n"
     ]
    }
   ],
   "source": [
    "ops = '+'\n",
    "\n",
    "num_inputs = 4\n",
    "total_syms = ['A','B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P']\n",
    "all_syms = total_syms[:num_inputs]\n",
    "all_input_vals = list(np.arange(2,18))\n",
    "input_vals = random.sample(all_input_vals,num_inputs)\n",
    "# randomly select values for each input\n",
    "cue_dict = {}\n",
    "for i, s in enumerate(all_syms):\n",
    "    cue_dict[s] = input_vals[i]\n",
    "    \n",
    "print(cue_dict)\n",
    "primitives = generate_primitives(all_syms, cue_dict)\n",
    "print(primitives)\n",
    "pos_primitives = generate_pos_primitives(all_syms, cue_dict)\n",
    "print(pos_primitives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2560e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainseqs  [[('+', 'A'), ('+', 'B'), '=', 19], [('+', 'B'), ('+', 'C'), '=', 7], [('+', 'C'), ('+', 'A'), '=', 20]]\n",
      "testseqs  [[('+', 'A'), ('+', 'A'), '=', 32], [('+', 'A'), ('+', 'B'), '=', 19], [('+', 'A'), ('+', 'C'), '=', 20], [('+', 'A'), ('+', 'D'), '=', 22], [('+', 'B'), ('+', 'A'), '=', 19], [('+', 'B'), ('+', 'B'), '=', 6], [('+', 'B'), ('+', 'C'), '=', 7], [('+', 'B'), ('+', 'D'), '=', 9], [('+', 'C'), ('+', 'A'), '=', 20], [('+', 'C'), ('+', 'B'), '=', 7], [('+', 'C'), ('+', 'C'), '=', 8], [('+', 'C'), ('+', 'D'), '=', 10], [('+', 'D'), ('+', 'A'), '=', 22], [('+', 'D'), ('+', 'B'), '=', 9], [('+', 'D'), ('+', 'C'), '=', 10], [('+', 'D'), ('+', 'D'), '=', 12]]\n",
      "run time:  0.01611565351486206\n",
      "fully trained models:  0\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'ft_train_acc' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6y/z1h4y1t94jvb186qws4p3qq40000gn/T/ipykernel_62808/1808503850.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'trainseqs '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainseqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'testseqs '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestseqs\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mres1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollect_accs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainseqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainseqs_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestseqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcue_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/6y/z1h4y1t94jvb186qws4p3qq40000gn/T/ipykernel_62808/2843371017.py\u001b[0m in \u001b[0;36mcollect_accs\u001b[0;34m(trainseqs, trainseqs_p, testseqs, cue_dict, num_inputs)\u001b[0m\n\u001b[1;32m     99\u001b[0m            \u001b[0;34m'dfs'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dfs_p'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdfs_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r2'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mr2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r2_p'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mr2_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'final_acc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfinal_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'final_acc_p'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfinal_acc_p\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m            \u001b[0;34m'final_acc_std'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfinal_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'final_acc_std_p'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfinal_acc_p\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m            'ft_train_acc':ft_train_acc,'ft_train_acc_p':ft_train_acc_p}\n\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'ft_train_acc' referenced before assignment"
     ]
    }
   ],
   "source": [
    "trainseqs = generate_pos_other(ops, all_syms[:-1], cue_dict)\n",
    "trainseqs_p = generate_pos_other(ops, all_syms[:-1], cue_dict) + pos_primitives\n",
    "testseqs = generate_pos_trials(ops, all_syms, all_syms, cue_dict)\n",
    "print('trainseqs ', trainseqs)\n",
    "print('testseqs ', testseqs )\n",
    "res1 = collect_accs(trainseqs, trainseqs_p, testseqs, cue_dict, num_inputs)\n",
    "\n",
    "fig, ax = plt.subplots(2,1)\n",
    "heatmap_acc_sign(num_inputs, res1['dfs1'], ax[0])\n",
    "heatmap_acc_sign(num_inputs, res1['dfs2'], ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d063cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239d2d7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
