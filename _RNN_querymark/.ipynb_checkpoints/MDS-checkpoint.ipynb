{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7edacb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import seaborn as sns \n",
    "from sklearn.metrics import r2_score\n",
    "import math\n",
    "import matplotlib as mpl\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.metrics.pairwise import manhattan_distances, euclidean_distances\n",
    "import scipy\n",
    "\n",
    "# ======\n",
    "current = os.path.dirname(os.path.realpath('plotting.py'))\n",
    "parent = os.path.dirname(current)\n",
    "sys.path.append(parent)\n",
    "from functions.rnn_cryptic_equals import convert_seq2inputs, calculate_output, onehot2seq "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "812ee653",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStepRNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_size, hidden_size, num_layers):\n",
    "        super(OneStepRNN, self).__init__()\n",
    "        # Define parameters\n",
    "        self.rnn = torch.nn.RNN(input_size=input_size,\n",
    "                        hidden_size=hidden_size,\n",
    "                        num_layers= num_layers,\n",
    "                        batch_first=True)\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        # Define the layers\n",
    "        self.input2hidden = nn.Linear(input_size + self.hidden_size, self.hidden_size)\n",
    "        self.fc1tooutput = nn.Linear(self.hidden_size, output_size)\n",
    "        self.initialize_weights()\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        combined = torch.cat((x, hidden), dim=0) ## dim = 1??\n",
    "        self.hidden = nn.functional.relu(self.input2hidden(combined))\n",
    "        self.output = self.fc1tooutput(self.hidden)\n",
    "        #return self.output.view(-1,output_size), self.hidden\n",
    "        return self.output, self.hidden\n",
    "\n",
    "    def get_activations(self, x, hidden):\n",
    "        self.forward(x, hidden)  # update the activations with the particular input\n",
    "        return self.hidden, self.output #, self.fc1_activations\n",
    "\n",
    "    def get_noise(self):\n",
    "        return self.hidden_noise\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)[0]\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight, 0.001)\n",
    "                \n",
    "def generate_trials(op, input_ids, init_values):\n",
    "    \n",
    "    ''' function for generating all permutations of 1 step trials '''\n",
    "    \n",
    "    seq = []\n",
    "    combi_inputcue = list(itertools.product(input_ids, repeat=1))\n",
    "    for init in init_values:\n",
    "        for cue in combi_inputcue:\n",
    "            seq.append([init,\n",
    "                        *zip(tuple(op), cue), '=']) #group per time point t\n",
    "    for s in seq:\n",
    "        s.append(calculate_output(s, cue_dict))\n",
    "    return seq\n",
    "\n",
    "def generate_primitives(inputs):\n",
    "    seq = []\n",
    "    for inp in inputs:\n",
    "        trial = [inp, '=']\n",
    "        trial.append(calculate_output(trial, cue_dict))\n",
    "        seq.append(trial)\n",
    "    return seq\n",
    "\n",
    "\n",
    "def generate_trials(op, input_ids, init_values):\n",
    "    \n",
    "    ''' function for generating all permutations of 1 step trials '''\n",
    "    \n",
    "    seq = []\n",
    "    combi_inputcue = list(itertools.product(input_ids, repeat=1))\n",
    "    for init in init_values:\n",
    "        for cue in combi_inputcue:\n",
    "            seq.append([init,\n",
    "                        *zip(tuple(op), cue), '=']) #group per time point t\n",
    "    for s in seq:\n",
    "        s.append(calculate_output(s, cue_dict))\n",
    "    return seq\n",
    "\n",
    "def generate_self(op, inputs):\n",
    "    seq = []\n",
    "    for inp in inputs:\n",
    "        trial = generate_trials(op, inp, inp)\n",
    "        seq += trial\n",
    "    return seq\n",
    "\n",
    "def generate_other(op, inputs):\n",
    "    seq = []\n",
    "    inputs1 = inputs.copy()\n",
    "    inputs2 = inputs.copy()\n",
    "    inputs2.append(inputs2.pop(0))\n",
    "    for i in range(len(inputs1)):\n",
    "        trial = [inputs1[i], (op, inputs2[i]), '=']\n",
    "        trial.append(calculate_output(trial, cue_dict))\n",
    "        seq.append(trial)\n",
    "    return seq\n",
    "\n",
    "def generate_other(op, inputs):\n",
    "    seq = []\n",
    "    inputs1 = inputs.copy()\n",
    "    inputs2 = inputs.copy()\n",
    "    inputs2.append(inputs2.pop(0))\n",
    "    for i in range(len(inputs1)):\n",
    "        trial = [inputs1[i], (op, inputs2[i]), '=']\n",
    "        trial.append(calculate_output(trial, cue_dict))\n",
    "        seq.append(trial)\n",
    "    return seq\n",
    "\n",
    "def generate_other_reverse(op, inputs):\n",
    "    seq = []\n",
    "    inputs1 = inputs.copy()\n",
    "    inputs2 = inputs.copy()\n",
    "    inputs2.append(inputs2.pop(0))\n",
    "    inputs2.append(inputs2.pop(0))\n",
    "    for i in range(len(inputs1)):\n",
    "        trial = [inputs1[i], (op, inputs2[i]), '=']\n",
    "        trial.append(calculate_output(trial, cue_dict))\n",
    "        seq.append(trial)\n",
    "    return seq\n",
    "\n",
    "def generate_other_reverse_primitives(op, inputs):\n",
    "    seq = []\n",
    "    inputs1 = inputs.copy()\n",
    "    inputs2 = inputs.copy()\n",
    "    n = int(len(inputs1)/2)\n",
    "    for i in range(n):\n",
    "        trial = [inputs1[i], (op, inputs2[i+n]), '=']\n",
    "        trial.append(calculate_output(trial, cue_dict))\n",
    "        seq.append(trial)\n",
    "    return seq\n",
    "\n",
    "def change_dict(seqs, new_dict):\n",
    "    \"\"\" recalculates sequence output\"\"\"\n",
    "    inps = [s[:-1] for s in seqs]\n",
    "    for inp in inps:\n",
    "        inp.append(calculate_output(inp, new_dict))\n",
    "    return inps\n",
    "\n",
    "\n",
    "## running function\n",
    "def get_reps(model, testdata, hidden_size):\n",
    "    model.eval()\n",
    "    trials = []\n",
    "    hiddens = []\n",
    "    for testset in testdata:\n",
    "        for x,y in testset:\n",
    "            for i in range(len(x)):\n",
    "                hidden_arr = np.empty((0,  hidden_size))\n",
    "                hidden = torch.zeros(1, hidden_size)[0]\n",
    "                for step in x[i]:\n",
    "                    hidden, y_hat = model.get_activations(step,hidden)\n",
    "                    hidden_arr = np.vstack([hidden_arr, hidden.detach().numpy()])\n",
    "            hiddens.append(hidden_arr)\n",
    "            trials.append(str(onehot2seq(x)))\n",
    "\n",
    "    return hiddens, trials \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "899299d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 5, 'B': 6, 'C': 11, 'D': 17}\n",
      "[['A', '=', 5], ['B', '=', 6], ['C', '=', 11], ['D', '=', 17]]\n",
      "[['A', ('+', 'C'), '=', 16], ['B', ('+', 'D'), '=', 23]]\n"
     ]
    }
   ],
   "source": [
    "ops = '+'\n",
    "\n",
    "num_inputs = 4\n",
    "total_syms = ['A','B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P']\n",
    "all_syms = total_syms[:num_inputs]\n",
    "all_input_vals = list(np.arange(2,18))\n",
    "input_vals = random.sample(all_input_vals,num_inputs)\n",
    "input_vals.sort()\n",
    "#Â randomly select values for each input\n",
    "cue_dict = {}\n",
    "for i, s in enumerate(all_syms):\n",
    "    cue_dict[s] = input_vals[i]\n",
    "    \n",
    "print(cue_dict)\n",
    "primitives = generate_primitives(all_syms)\n",
    "rp = generate_other_reverse_primitives('+', all_syms)\n",
    "print(primitives)\n",
    "print(rp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "342dbcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "num_classes = 22\n",
    "batchsize=1\n",
    "\n",
    "# RNN specs\n",
    "input_size = num_classes\n",
    "output_size = 1\n",
    "num_layers = 1\n",
    "hidden_size = 20\n",
    "learningRate = 0.005\n",
    "\n",
    "## running params\n",
    "epochs = 1200\n",
    "num_sims = 104"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31f95408",
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate distance matrices for all models and steps \n",
    "\n",
    "def calculate_RDMs(res):\n",
    "    ## find indices of 100% acc rnns\n",
    "    acc_df = res['acc_df']\n",
    "    all_acc_mods = acc_df[(acc_df['acc_train'] == 1) & (acc_df['acc_train_p'] == 1)].index\n",
    "    print('no. 100% trained RNNs: ', len(all_acc_mods))\n",
    "\n",
    "    mod_list = all_acc_mods # choose only rnns trained to 100%\n",
    "    # mod_list = np.arange(num_sims)\n",
    "\n",
    "    # initialise empty lists/arrays\n",
    "    rdms = [[] for _ in range(4)]\n",
    "    rdms_p = [[] for _ in range(4)]\n",
    "\n",
    "    # extracts results from dictionary\n",
    "    mods = res['mods']\n",
    "    mods_p = res['mods_p']\n",
    "    cue_dicts = res['cue_dicts']\n",
    "    testseq = generate_trials(ops, all_syms, all_syms)\n",
    "    ft_cue_dicts = [cue_dicts[j] for j in mod_list]\n",
    "\n",
    "    for ind, m in enumerate(mod_list): # for each model \n",
    "        \n",
    "        testseqs = change_dict(testseq, cue_dicts[m])\n",
    "        train_inputs = convert_seq2inputs(testseq, num_classes=num_classes, seq_len=5)\n",
    "        testset = DataLoader(train_inputs, batch_size=batchsize, shuffle=False)\n",
    "        \n",
    "        # get activations for control model\n",
    "        hiddens, trials = get_reps(mods[m], [testset], hidden_size)\n",
    "        for h in range(4): \n",
    "            hid_vals = np.array([hid[h,:] for hid in hiddens]) # combine activations from each trial for the time step\n",
    "            rep_mat = euclidean_distances(hid_vals) #Â calculate euclidean distance matrix between trials\n",
    "            rdms[h].append(rep_mat)\n",
    "            \n",
    "        # get activations for primitive trained model\n",
    "        hiddens_p, trials = get_reps(mods_p[m], [testset], hidden_size)    \n",
    "        for h in range(4):\n",
    "            hid_vals = np.array([hid[h,:] for hid in hiddens_p])\n",
    "            rep_mat = euclidean_distances(hid_vals)\n",
    "            rdms_p[h].append(rep_mat)\n",
    "            \n",
    "    return {'rdms': rdms, 'rdms_p': rdms_p, 'ft_cue_dicts': ft_cue_dicts}\n",
    "\n",
    "rank_dict = {'A': -1.5, 'B': -0.5, 'C': 0.5, 'D': 1.5}\n",
    "\n",
    "def regress_RDM_abs(time_step, rdm, ft_cue_dicts, ranked = False):\n",
    "    rs = []\n",
    "    for i, cuedict in enumerate(ft_cue_dicts):\n",
    "        if ranked:\n",
    "            curr_tests = change_dict(testseqs, rank_dict)\n",
    "        else:\n",
    "            curr_tests = change_dict(testseqs, cuedict)\n",
    "        truth_outs = [t[-1] for t in curr_tests]\n",
    "        truth_RDM = abs(np.array([truth_outs]*16) - np.array([truth_outs]*16).T)\n",
    "        x = rdm[time_step][i].reshape(-1,1)\n",
    "        y = truth_RDM.reshape(16*16)\n",
    "        model = LinearRegression().fit(x, y)\n",
    "        r_sq = model.score(x, y)\n",
    "        rs.append(r_sq)\n",
    "    return rs\n",
    "\n",
    "def regress_RDM_abs_init(time_step, rdm, ft_cue_dicts, ranked = False):\n",
    "    rs = []\n",
    "    for i, cuedict in enumerate(ft_cue_dicts):\n",
    "        if ranked:\n",
    "            curr_tests = change_dict(testseqs, rank_dict)\n",
    "        else:\n",
    "            curr_tests = change_dict(testseqs, cuedict)\n",
    "        init_tests = [[t[0]]+['='] for t in curr_tests ]\n",
    "        truth_outs = [calculate_output(t, cuedict) for t in init_tests]\n",
    "        truth_RDM = abs(np.array([truth_outs]*16) - np.array([truth_outs]*16).T)\n",
    "        x = rdm[time_step][i].reshape(-1,1)\n",
    "        y = truth_RDM.reshape(16*16)\n",
    "        model = LinearRegression().fit(x, y)\n",
    "        r_sq = model.score(x, y)\n",
    "        rs.append(r_sq)\n",
    "    return rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3de943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "737fb929",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b8bce94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "\n",
    "save_dir = '../results/representation_analysis/'\n",
    "\n",
    "with open(save_dir+'other/res_other', 'rb') as f:\n",
    "    res1 = pickle.load(f)\n",
    "    \n",
    "with open(save_dir+'full/res_full', 'rb') as f:\n",
    "    res2 = pickle.load(f)\n",
    "    \n",
    "with open(save_dir+'balanced_other/res_balanced', 'rb') as f:\n",
    "    res3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cc728f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75367455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5391cd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = 6, 6\n",
    "fig, axs = plt.subplots(2,2, subplot_kw=dict(projection='3d'))\n",
    "\n",
    "for j, dist in enumerate(distmats):\n",
    "    mds = MDS(dissimilarity='precomputed',random_state=0, n_components=3)\n",
    "    X_transform = mds.fit_transform(dist)\n",
    "    ax = axs[math.floor(j/2), j%2]\n",
    "    ax.title.set_text('step: '+str(j))\n",
    "    for i in range(len(trials)):\n",
    "        ax.scatter(X_transform[i,0], X_transform[i,1],X_transform[i,2], color = colors1[i])\n",
    "        ax.scatter(X_transform[i,0], X_transform[i,1],X_transform[i,2], s=100, facecolors='none', edgecolors=colors2[i])\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b58f03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
