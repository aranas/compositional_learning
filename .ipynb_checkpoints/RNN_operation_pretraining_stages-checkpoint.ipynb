{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62353cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca057a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions.plotting as NNplt\n",
    "from functions.rnn_sequences import generate_sequences, convert_seq2inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7224476e",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cacc5265",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStepRNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_size, hidden_size, num_layers):\n",
    "        super(OneStepRNN, self).__init__()\n",
    "        # Define parameters\n",
    "        self.rnn = torch.nn.RNN(input_size=input_size,\n",
    "                        hidden_size=hidden_size,\n",
    "                        num_layers= num_layers,\n",
    "                        batch_first=True)\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        # Define the layers\n",
    "        self.input2hidden = nn.Linear(input_size + self.hidden_size, self.hidden_size)\n",
    "        self.fc1tooutput = nn.Linear(self.hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        combined = torch.cat((x, hidden), dim=0) ## dim = 1??\n",
    "        self.hidden = nn.functional.relu(self.input2hidden(combined))\n",
    "        self.output = self.fc1tooutput(self.hidden)\n",
    "        #return self.output.view(-1,output_size), self.hidden\n",
    "        return self.output, self.hidden\n",
    "\n",
    "    def get_activations(self, x, hidden):\n",
    "        self.forward(x, hidden)  # update the activations with the particular input\n",
    "        return self.hidden, self.output #, self.fc1_activations\n",
    "\n",
    "    def get_noise(self):\n",
    "        return self.hidden_noise\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)[0]\n",
    "\n",
    "\n",
    "def train(sequence,label,model,optimizer,criterion):\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    #Read each cue in and keep hidden state for next cue\n",
    "    hidden = model.initHidden()\n",
    "    for i in range(len(sequence[0])):\n",
    "        output, hidden = model.forward(sequence[0][i], hidden)\n",
    "    #Compare final output to target\n",
    "    loss = criterion(output,label)#.long())\n",
    "    #Back-propagate\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return output, loss.item()\n",
    "\n",
    "def run(model, train_data, epochs):\n",
    "\n",
    "    model.train()\n",
    "    loss_history = []\n",
    "    for epoch in range(epochs):\n",
    "        lossTotal = []\n",
    "        ys = []\n",
    "        for x,y in train_data:\n",
    "            output, loss = train(x,y,model,optimizer,criterion)\n",
    "            lossTotal.append(loss) # append MSE\n",
    "            ys.append(y.item())\n",
    "        cv_rmse = np.mean(lossTotal)**0.5/np.mean(ys) # CV_RMSE = RMSE/y_mu\n",
    "        loss_history.append(cv_rmse)\n",
    "        \n",
    "        ### TODO: better CV(RMSE) = RMSE/mean\n",
    "\n",
    "    print(f'CV_RMSE: {round(cv_rmse*100, 1)} %')\n",
    "    return loss_history\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4151b5d2",
   "metadata": {},
   "source": [
    "# Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de0e071e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1step:  16\n",
      "2step:  128\n",
      "2 step prim:  128\n"
     ]
    }
   ],
   "source": [
    "operators = ['+', '*']\n",
    "input_ids = ['A', 'B', 'C', 'D'] \n",
    "init_values = [1,6]\n",
    "convert_inputcue = {'A': 2, \n",
    "                    'B': 3,\n",
    "                    'C': 5,\n",
    "                    'D': 7}\n",
    "\n",
    "# 1 step\n",
    "len_seq = 1\n",
    "seq_1 = generate_sequences(operators, input_ids, len_seq, init_values)\n",
    "seqs_1 = convert_seq2inputs(seq_1, num_classes=13, seq_len=3)\n",
    "train_data_1 = DataLoader(seqs_1, batch_size=1, shuffle=True)\n",
    "\n",
    "# 2 step\n",
    "len_seq = 2\n",
    "seq_2 = generate_sequences(operators, input_ids, len_seq, init_values)\n",
    "seqs_2 = convert_seq2inputs(seq_2, num_classes=13, seq_len=5)\n",
    "train_data_2 = DataLoader(seqs_2, batch_size=1, shuffle=True)\n",
    "\n",
    "# 2 step primitive\n",
    "len_seq = 2\n",
    "input_ids = [2,3,5,7] \n",
    "seq_prim = generate_sequences(operators, input_ids, len_seq, init_values, cue_dict = False)\n",
    "seqs_prim = convert_seq2inputs(seq_prim, num_classes=13, seq_len=5, primitive_type = 'op')\n",
    "train_data_prim = DataLoader(seqs_2, batch_size=1, shuffle=True)\n",
    "\n",
    "print('1step: ', len(seqs_1))\n",
    "print('2step: ', len(seqs_2))\n",
    "print('2 step prim: ', len(seqs_prim))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e80f40",
   "metadata": {},
   "source": [
    "# Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b3655852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "num_classes = 13\n",
    "input_size = num_classes\n",
    "output_size = 1\n",
    "hidden_size = 20\n",
    "num_layers = 1\n",
    "epochs = 250\n",
    "learningRate = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4185ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### rep 0  ###\n",
      "CV_RMSE: 8.6 %\n",
      "CV_RMSE: 5.5 %\n",
      "### rep 1  ###\n",
      "CV_RMSE: 8.2 %\n",
      "CV_RMSE: 7.5 %\n",
      "### rep 2  ###\n",
      "CV_RMSE: 28.7 %\n",
      "CV_RMSE: 11.7 %\n",
      "### rep 3  ###\n",
      "CV_RMSE: 13.0 %\n",
      "CV_RMSE: 8.3 %\n",
      "### rep 4  ###\n",
      "CV_RMSE: 5.1 %\n",
      "CV_RMSE: 5.1 %\n",
      "### rep 5  ###\n",
      "CV_RMSE: 34.4 %\n",
      "CV_RMSE: 7.6 %\n",
      "### rep 6  ###\n",
      "CV_RMSE: 13.3 %\n",
      "CV_RMSE: 38.9 %\n",
      "### rep 7  ###\n",
      "CV_RMSE: 8.6 %\n",
      "CV_RMSE: 3.1 %\n",
      "### rep 8  ###\n",
      "CV_RMSE: 15.7 %\n",
      "CV_RMSE: 16.7 %\n",
      "### rep 9  ###\n",
      "CV_RMSE: 7.1 %\n",
      "CV_RMSE: 6.4 %\n",
      "### rep 10  ###\n",
      "CV_RMSE: 3.0 %\n"
     ]
    }
   ],
   "source": [
    "num_sims = 100\n",
    "epochs = 300\n",
    "\n",
    "## train on 3 task 200, 200, 200\n",
    "losses_prim = []\n",
    "for j in range(num_sims):\n",
    "    print('### rep', j, ' ###')\n",
    "    model = OneStepRNN(input_size, output_size, hidden_size, num_layers)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learningRate)\n",
    "    loss1 = run(model, train_data_prim, epochs)\n",
    "    loss2 = run(model, train_data_2, epochs)\n",
    "    loss12 = loss1+loss2\n",
    "    losses_prim.append(loss12)\n",
    "    \n",
    "## train on 3 task 200, 200, 200\n",
    "losses_2 = []\n",
    "for j in range(num_sims):\n",
    "    print('### rep', j, ' ###')\n",
    "    model = OneStepRNN(input_size=input_size, output_size=output_size, hidden_size=hidden_size, num_layers=num_layers)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learningRate)\n",
    "    loss2 = run(model, train_data_2, epochs)\n",
    "    losses_2.append(loss2)\n",
    "   \n",
    "save_dir = 'results/op_pretraining/cont_1/'\n",
    "\n",
    " # save predictions\n",
    "fileObject = open(save_dir + 'losses_prim', 'wb')\n",
    "pickle.dump(losses_prim , fileObject)\n",
    "fileObject.close()\n",
    "\n",
    "fileObject = open(save_dir + 'losses_2', 'wb')\n",
    "pickle.dump(losses_2 , fileObject)\n",
    "fileObject.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ec2098",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd151f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407f24b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
