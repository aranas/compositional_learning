{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0264f288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import seaborn as sns \n",
    "current = os.path.dirname(os.path.realpath('plotting.py'))\n",
    "parent = os.path.dirname(current)\n",
    "sys.path.append(parent)\n",
    "import functions.plotting as NNplt\n",
    "from functions.rnn_cryptic import generate_sequences, convert_seq2inputs,\\\n",
    "                                  pad_seqs_2step, pad_seqs_1step, calculate_output, onehot2seq \n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a55f6d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStepRNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_size, hidden_size, num_layers):\n",
    "        super(OneStepRNN, self).__init__()\n",
    "        # Define parameters\n",
    "        self.rnn = torch.nn.RNN(input_size=input_size,\n",
    "                        hidden_size=hidden_size,\n",
    "                        num_layers= num_layers,\n",
    "                        batch_first=True)\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        # Define the layers\n",
    "        self.input2hidden = nn.Linear(input_size + self.hidden_size, self.hidden_size)\n",
    "        self.fc1tooutput = nn.Linear(self.hidden_size, output_size)\n",
    "        self.initialize_weights()\n",
    "    def forward(self, x, hidden):\n",
    "        combined = torch.cat((x, hidden), dim=0) ## dim = 1??\n",
    "        self.hidden = nn.functional.relu(self.input2hidden(combined))\n",
    "        self.output = self.fc1tooutput(self.hidden)\n",
    "        #return self.output.view(-1,output_size), self.hidden\n",
    "        return self.output, self.hidden\n",
    "\n",
    "    def get_activations(self, x, hidden):\n",
    "        self.forward(x, hidden)  # update the activations with the particular input\n",
    "        return self.hidden, self.output #, self.fc1_activations\n",
    "\n",
    "    def get_noise(self):\n",
    "        return self.hidden_noise\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)[0]\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        y = 1/math.sqrt(hidden_size)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight, 0.01)\n",
    "\n",
    "\n",
    "def train(sequence,label,model,optimizer,criterion):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    #Read each cue in and keep hidden state for next cue\n",
    "    hidden = model.initHidden()\n",
    "    batch_out = []\n",
    "    for batchseq in sequence:\n",
    "        for i in range(len(batchseq)):\n",
    "            output, hidden = model.forward(batchseq[i], hidden)\n",
    "        batch_out.append(output)\n",
    "        #Compare final output to target\n",
    "    batch_out = torch.cat(batch_out)\n",
    "    loss = criterion(batch_out,label)#.long())\n",
    "\n",
    "    #Back-propagate\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return batch_out, loss.item()\n",
    "\n",
    "def run_acc(model,optimizer,criterion, train_data, test_data, epochs, verbose = False):\n",
    "    \n",
    "    loss_history = np.empty((0,1))\n",
    "    all_accs = np.empty((0,len(test_data)))\n",
    "    for epoch in range(epochs):\n",
    "        lossTotal = 0\n",
    "        for i, (x,y) in enumerate(train_data):\n",
    "            output, loss = train(x,y,model,optimizer,criterion)\n",
    "            lossTotal += loss # add MSE -> sum of square errors \n",
    "        loss_history = np.vstack([loss_history, lossTotal])\n",
    "        acc = test_acc(model, test_data, hidden_size)\n",
    "        all_accs = np.vstack([all_accs,acc])\n",
    "\n",
    "    return loss_history, all_accs\n",
    "\n",
    "def test_acc(model, testdata, hidden_size, verbose = False):\n",
    "    model.eval()\n",
    "    accs = np.empty((1, 0))\n",
    "    for testset in testdata:\n",
    "        batch_correct = []\n",
    "        for x,y in testset:\n",
    "            correct = 0\n",
    "            for i in range(len(x)):\n",
    "                hidden = torch.zeros(1, hidden_size)[0]\n",
    "                for step in x[i]:\n",
    "                    hidden, y_hat = model.get_activations(step,hidden)\n",
    "                correct += sum(torch.round(y[i]) == torch.round(y_hat)).item()\n",
    "            batch_correct.append(correct/len(y))\n",
    "        acc = np.mean(batch_correct)\n",
    "        accs = np.append(accs, [acc])\n",
    "    if verbose:\n",
    "        print('test accuracy: %f ' % (acc))\n",
    "    return accs\n",
    "\n",
    "def test_preds(model, testdata, hidden_size, suffix = ''):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    labs = []\n",
    "    trials = []\n",
    "    accs = []\n",
    "    for testset in testdata:\n",
    "        batch_correct = []\n",
    "        for x,y in testset:\n",
    "            for i in range(len(x)):\n",
    "                hidden = torch.zeros(1, hidden_size)[0]\n",
    "                for step in x[i]:\n",
    "                    hidden, y_hat = model.get_activations(step,hidden)\n",
    "                preds.append(y_hat.detach().item())\n",
    "                labs.append(y[i].detach().item())\n",
    "                correct = sum(torch.round(y[i]) == torch.round(y_hat)).item()\n",
    "                accs.append(correct)\n",
    "            trials.append(str(onehot2seq(x)))\n",
    "    df = pd.DataFrame({'trial':trials, 'label'+suffix:labs, 'pred'+suffix: preds, 'acc'+suffix: accs})\n",
    "    return df \n",
    "\n",
    "\n",
    "def shuffle_weights(model):\n",
    "    model2 = OneStepRNN(input_size, output_size, hidden_size, num_layers)\n",
    "    mod_dict = model.state_dict()\n",
    "    shuffled_dict = {layer: shuffle_tensor(val) for layer, val in mod_dict.items()}\n",
    "    model2.load_state_dict(shuffled_dict)\n",
    "    return model2\n",
    "\n",
    "def shuffle_tensor(t):\n",
    "    idx = torch.randperm(t.nelement())\n",
    "    t = t.view(-1)[idx].view(t.size())\n",
    "    return t\n",
    "\n",
    "def run_sim(train_trials, test_trials):\n",
    "    model = OneStepRNN(input_size, output_size, hidden_size, num_layers)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learningRate)\n",
    "    loss1, acc1 = run_acc(model,optimizer,criterion, train_trials, test_trials, epochs)\n",
    "    return loss1, acc1, model\n",
    "\n",
    "def run_sims(i, train_trials, test_trials):\n",
    "    print('##########Â rep', i, '#########')\n",
    "    model = OneStepRNN(input_size, output_size, hidden_size, num_layers)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learningRate)\n",
    "    loss1, acc1 = run_acc(model,optimizer,criterion, train_trials[0], test_trials, epochs)\n",
    "    loss2, acc2 = run_acc(model,optimizer,criterion, train_trials[1], test_trials, epochs)\n",
    "    losses = np.vstack([loss1,loss2])\n",
    "    accs = np.vstack([acc1,acc2])\n",
    "    return losses, accs, model\n",
    "\n",
    "def change_padder(seqs, cue_dict, xval):\n",
    "    \"\"\" changes value of X from zero to a new value\n",
    "        and recalculates sequence output\"\"\"\n",
    "    cue_dict['X'] = xval\n",
    "    inps = [s[:-1] for s in seqs]\n",
    "    for inp in inps:\n",
    "        inp.append(calculate_output(inp, cue_dict, bidmas = False))\n",
    "\n",
    "    return inps, cue_dict\n",
    "\n",
    "def change_dict(seqs, new_dict):\n",
    "    \"\"\" recalculates sequence output\"\"\"\n",
    "    inps = [s[:-1] for s in seqs]\n",
    "    for inp in inps:\n",
    "        inp.append(calculate_output(inp, new_dict, bidmas = False))\n",
    "\n",
    "    return inps, cue_dict\n",
    "\n",
    "def predcorr(mods, tests):\n",
    "    dfs1 = []\n",
    "    for i in range(len(mods)):\n",
    "        df = test_preds(mods[i], [tests[i]], hidden_size)\n",
    "        dfs1.append(df)\n",
    "        all_dfs1 = pd.concat(dfs1) \n",
    "        preds, labs = all_dfs1['pred'], all_dfs1['label']\n",
    "        xy = np.arange(np.min(preds)-1, np.max(labs)+1, 0.1)\n",
    "\n",
    "        for d in dfs1:\n",
    "            plt.scatter(d['label'], d['pred'])\n",
    "        plt.plot(xy,xy)\n",
    "        plt.xlabel('Ground truth')\n",
    "        plt.ylabel('Model prediction')\n",
    "        plt.title('with primitive training, R^2 = ' + str(round(r2_score(all_dfs1['pred'],all_dfs1['label']), 2)) )\n",
    "        df_final = all_dfs1.groupby(['trial']).mean().sort_values(by = 'acc' , ascending=False)\n",
    "        print(df_final)\n",
    "    \n",
    "    return df_final\n",
    "\n",
    "# ----------\n",
    "# plotting\n",
    "# ----------\n",
    "\n",
    "def plotNNs(loss_arrays, acc_arrays, labels, colors, title, shift = 0):\n",
    "\n",
    "    fig, axs = plt.subplots(2, 1)\n",
    "    loss_cols = ['blue', 'darkblue']\n",
    "    loss_labs = ['loss_with_primitive', 'loss_without_primitive']\n",
    "    for i, arr in enumerate(loss_arrays):\n",
    "        x = np.arange(0,arr.shape[0],1) + shift\n",
    "        mn = arr.mean(axis=1)\n",
    "        errs = arr.std(axis=1)\n",
    "        \n",
    "        axs[0].plot(x, mn, label = loss_labs[i], color = loss_cols[i])\n",
    "        axs[0].fill_between(x, mn - errs, mn + errs, alpha = 0.3, facecolor = loss_cols[i])\n",
    "    \n",
    "    axs[0].set_xlabel('epoch')\n",
    "    axs[0].set_ylabel('loss')\n",
    "    axs[0].legend()\n",
    "    \n",
    "    for i, arr in enumerate(acc_arrays):\n",
    "        x = np.arange(0,arr.shape[0],1) + shift\n",
    "        mn = arr.mean(axis=1)\n",
    "        errs = arr.std(axis=1)\n",
    "        \n",
    "        axs[1].plot(x, mn, label = labels[i], color = colors[i])\n",
    "        axs[1].fill_between(x, mn - errs, mn + errs, alpha = 0.3, facecolor = colors[i])\n",
    "    \n",
    "    axs[1].set_xlabel('epoch')\n",
    "    axs[1].set_ylabel('accuracy')\n",
    "    axs[1].legend()\n",
    "\n",
    "    fig.suptitle(title, fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f2e0ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_other(operators, inputs, init_values, rep = 1):\n",
    "    # remove init form inputs\n",
    "    \n",
    "    seq = []\n",
    "    combi_operators = list(itertools.product(operators, repeat=2))\n",
    "    for _ in range(rep):\n",
    "        for init in init_values:\n",
    "            input_ids = [val for val in inputs if val != init]\n",
    "            combi_inputcue = list(itertools.combinations(input_ids, r=2))\n",
    "            cue = random.choice(combi_inputcue)\n",
    "            op = random.choice(combi_operators)\n",
    "            trial = [init,*zip(tuple(op), cue)]\n",
    "            trial.append(calculate_output(trial, cue_dict, False))\n",
    "            seq.append(trial)\n",
    "\n",
    "    return seq\n",
    "\n",
    "def test_other(operators, test, syms, rep = 1):\n",
    "    # remove init form inputs\n",
    "    \n",
    "    seq = []\n",
    "    combi_operators = list(itertools.product(operators, repeat=2))\n",
    "    for _ in range(rep):\n",
    "        input_ids = [test] + [random.choice(syms)]\n",
    "        random.shuffle(input_ids)\n",
    "        combi_inputcue = list(itertools.combinations(input_ids, r=2))\n",
    "        cue = random.choice(combi_inputcue)\n",
    "        op = random.choice(combi_operators)\n",
    "        trial = [random.choice(syms),*zip(tuple(op), cue)]\n",
    "        trial.append(calculate_output(trial, cue_dict, False))\n",
    "        seq.append(trial)\n",
    "\n",
    "    return seq\n",
    "\n",
    "def generate_self(operators, inputs, rep = 1):\n",
    "    seq = []\n",
    "    for _ in range(rep):\n",
    "        for inp in inputs:\n",
    "            trial = generate_sequences(operators, inp, len_seq = 2, cue_dict = cue_dict, init_values = inp)\n",
    "            seq += trial\n",
    "    return seq\n",
    "\n",
    "def generate_dummy(operators, inputs, init_values, rep = 1):\n",
    "    # remove init form inputs\n",
    "    \n",
    "    seq = []\n",
    "    combi_operators = list(itertools.product(operators, repeat=2))\n",
    "    for _ in range(rep):\n",
    "        for init in init_values:\n",
    "            input_ids = [val for val in inputs if val != init]\n",
    "            inp = random.choice(input_ids)\n",
    "            cue = (inp, inp)\n",
    "            op = random.choice(combi_operators)\n",
    "            trial = [init,*zip(tuple(op), cue)]\n",
    "            trial.append(calculate_output(trial, cue_dict, False))\n",
    "            seq.append(trial)\n",
    "\n",
    "    return seq\n",
    "\n",
    "def generate_other_1step(operators, inputs, init_values):\n",
    "    # remove init form inputs\n",
    "    \n",
    "    seq = []\n",
    "    for init in init_values:\n",
    "        input_ids = [val for val in inputs if val != init]\n",
    "        cue = random.sample(input_ids, 2)\n",
    "        op = random.choice(operators)\n",
    "        trial = [init,(op, cue[0])]\n",
    "        trial.append(calculate_output(trial, cue_dict, False))\n",
    "        seq.append(trial)\n",
    "        op = random.choice(operators)\n",
    "        trial = [cue[1],(op, init)]\n",
    "        trial.append(calculate_output(trial, cue_dict, False))\n",
    "        seq.append(trial)\n",
    "\n",
    "    return seq\n",
    "\n",
    "def generate_min_other(operators, inputs, init_values):\n",
    "\n",
    "    seq = []\n",
    "    for inp in inputs:\n",
    "        inits = [val for val in init_values if val != inp]\n",
    "        init = random.choice(inits)\n",
    "        op = random.choice(operators)\n",
    "        trial = [init,(op, inp)]\n",
    "        trial.append(calculate_output(trial, cue_dict, False))\n",
    "        seq.append(trial)\n",
    "        \n",
    "    return seq\n",
    "\n",
    "\n",
    "def generate_Xother(operators, inputs):\n",
    "    # remove init form inputs\n",
    "    \n",
    "    seq = []\n",
    "    for inp in inputs:\n",
    "        op = random.choice(operators)\n",
    "        trial = ['X',(op, inp)]\n",
    "        trial.append(calculate_output(trial, cue_dict, False))\n",
    "        seq.append(trial)\n",
    "        \n",
    "    return seq\n",
    "\n",
    "def generate_self_1step(operators, inputs, init_values):  \n",
    "    seq = []\n",
    "    for init in init_values:\n",
    "        op = random.choice(operators)\n",
    "        trial = [init,(op, init)]\n",
    "        trial.append(calculate_output(trial, cue_dict, False))\n",
    "        seq.append(trial)\n",
    "    \n",
    "    return seq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8165d35a",
   "metadata": {},
   "source": [
    "# Parameters and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4843635a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exp1(trainseqs_old, testseqs_old):\n",
    "    \n",
    "    total_syms = ['A','B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P']\n",
    "    all_syms = total_syms[:num_inputs]\n",
    "    all_input_vals = list(np.arange(2,18))\n",
    "    input_vals = random.sample(all_input_vals,num_inputs)\n",
    "    #Â randomly select values for each input\n",
    "    for i, s in enumerate(all_syms):\n",
    "        cue_dict[s] = input_vals[i]\n",
    "    \n",
    "    # load data for primitive training\n",
    "    trainseqs, cd = change_dict(trainseqs_old, cue_dict)\n",
    "    train_inputs = convert_seq2inputs(trainseqs, num_classes=num_classes, seq_len=5)\n",
    "    trainset = DataLoader(train_inputs, batch_size=batchsize, shuffle=True)\n",
    "    testseqs, cd = change_dict(testseqs_old, cue_dict)\n",
    "    test_inputs = convert_seq2inputs(testseqs, num_classes=num_classes, seq_len=5)\n",
    "    testset = DataLoader(test_inputs, batch_size=batchsize, shuffle=True)\n",
    "\n",
    "    # run primitive training RNN\n",
    "    model = OneStepRNN(input_size, output_size, hidden_size, num_layers)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learningRate)\n",
    "    loss1, acc1 = run_acc(model,optimizer,criterion, trainset, [trainset, testset], epochs)\n",
    "\n",
    "    \n",
    "    return {'cue_dict':cue_dict, 'loss':loss1, 'acc':acc1, 'mod': model, 'test': testset}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5475df79",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "\n",
    "With P\n",
    "1. All permutations of 2 step + p\n",
    "2. All permutations of 1 step + p\n",
    "3. Only \"Other\" permutations of 1 step (B+C),(C+D) ... + p\n",
    "4. Only \"Self\" permutations of 1 step (B+B),(D+D) ... + p\n",
    "5. Min set of Xother (X+C),(X+B) .. + p\n",
    "\n",
    "Without P\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfce32da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "\n",
    "# data\n",
    "num_classes = 22\n",
    "batchsize=1\n",
    "\n",
    "# RNN specs\n",
    "input_size = num_classes\n",
    "output_size = 1\n",
    "num_layers = 1\n",
    "hidden_size = 20\n",
    "learningRate = 0.001\n",
    "\n",
    "## running params\n",
    "epochs = 1000\n",
    "num_sims = 80\n",
    "num_inputs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e14183",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba72d4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'X': 0, 'A': 13, 'B': 6, 'C': 15, 'D': 16, 'E': 4}\n"
     ]
    }
   ],
   "source": [
    "total_syms = ['A','B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P']\n",
    "all_syms = total_syms[:num_inputs]\n",
    "all_input_vals = list(np.arange(2,18))\n",
    "input_vals = random.sample(all_input_vals,num_inputs)\n",
    "#Â randomly select values for each input\n",
    "cue_dict = {'X':0}\n",
    "for i, s in enumerate(all_syms):\n",
    "    cue_dict[s] = input_vals[i]\n",
    "    \n",
    "print(cue_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db97c26",
   "metadata": {},
   "source": [
    "# 1. All permuatations of 2 step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14559f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "## running params\n",
    "epochs = 1000\n",
    "num_sims = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ebcd4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf331012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db349c2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
