{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0264f288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import seaborn as sns \n",
    "current = os.path.dirname(os.path.realpath('plotting.py'))\n",
    "parent = os.path.dirname(current)\n",
    "sys.path.append(parent)\n",
    "import functions.plotting as NNplt\n",
    "from functions.rnn_cryptic import generate_sequences, convert_seq2inputs,\\\n",
    "                                  pad_seqs_2step, pad_seqs_1step, calculate_output, onehot2seq \n",
    "\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a55f6d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStepRNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_size, hidden_size, num_layers):\n",
    "        super(OneStepRNN, self).__init__()\n",
    "        # Define parameters\n",
    "        self.rnn = torch.nn.RNN(input_size=input_size,\n",
    "                        hidden_size=hidden_size,\n",
    "                        num_layers= num_layers,\n",
    "                        batch_first=True)\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        # Define the layers\n",
    "        self.input2hidden = nn.Linear(input_size + self.hidden_size, self.hidden_size)\n",
    "        self.fc1tooutput = nn.Linear(self.hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        combined = torch.cat((x, hidden), dim=0) ## dim = 1??\n",
    "        self.hidden = nn.functional.relu(self.input2hidden(combined))\n",
    "        self.output = self.fc1tooutput(self.hidden)\n",
    "        #return self.output.view(-1,output_size), self.hidden\n",
    "        return self.output, self.hidden\n",
    "\n",
    "    def get_activations(self, x, hidden):\n",
    "        self.forward(x, hidden)  # update the activations with the particular input\n",
    "        return self.hidden, self.output #, self.fc1_activations\n",
    "\n",
    "    def get_noise(self):\n",
    "        return self.hidden_noise\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)[0]\n",
    "\n",
    "\n",
    "def train(sequence,label,model,optimizer,criterion):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    #Read each cue in and keep hidden state for next cue\n",
    "    hidden = model.initHidden()\n",
    "    batch_out = []\n",
    "    for batchseq in sequence:\n",
    "        for i in range(len(batchseq)):\n",
    "            output, hidden = model.forward(batchseq[i], hidden)\n",
    "        batch_out.append(output)\n",
    "        #Compare final output to target\n",
    "    batch_out = torch.cat(batch_out)\n",
    "    loss = criterion(batch_out,label)#.long())\n",
    "\n",
    "    #Back-propagate\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return batch_out, loss.item()\n",
    "\n",
    "def run_acc(model,optimizer,criterion, train_data, test_data, epochs, verbose = False):\n",
    "    \n",
    "    loss_history = np.empty((0,1))\n",
    "    all_accs = np.empty((0,len(test_data)))\n",
    "    for epoch in range(epochs):\n",
    "        lossTotal = 0\n",
    "        for i, (x,y) in enumerate(train_data):\n",
    "            output, loss = train(x,y,model,optimizer,criterion)\n",
    "            lossTotal += loss # add MSE -> sum of square errors \n",
    "        loss_history = np.vstack([loss_history, lossTotal])\n",
    "        acc = test_acc(model, test_data, hidden_size)\n",
    "        all_accs = np.vstack([all_accs,acc])\n",
    "\n",
    "    print(f'loss: {round(lossTotal,1)} ')\n",
    "    return loss_history, all_accs\n",
    "\n",
    "def test_acc(model, testdata, hidden_size, verbose = False):\n",
    "    model.eval()\n",
    "    accs = np.empty((1, 0))\n",
    "    for testset in testdata:\n",
    "        batch_correct = []\n",
    "        for x,y in testset:\n",
    "            correct = 0\n",
    "            for i in range(len(x)):\n",
    "                hidden = torch.zeros(1, hidden_size)[0]\n",
    "                for step in x[i]:\n",
    "                    hidden, y_hat = model.get_activations(step,hidden)\n",
    "                correct += sum(torch.round(y[i]) == torch.round(y_hat)).item()\n",
    "            batch_correct.append(correct/len(y))\n",
    "        acc = np.mean(batch_correct)\n",
    "        accs = np.append(accs, [acc])\n",
    "    if verbose:\n",
    "        print('test accuracy: %f ' % (acc))\n",
    "    return accs\n",
    "\n",
    "def test_preds(model, testdata, hidden_size, suffix = ''):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    labs = []\n",
    "    trials = []\n",
    "    for testset in testdata:\n",
    "        batch_correct = []\n",
    "        for x,y in testset:\n",
    "            correct = 0\n",
    "            for i in range(len(x)):\n",
    "                hidden = torch.zeros(1, hidden_size)[0]\n",
    "                for step in x[i]:\n",
    "                    hidden, y_hat = model.get_activations(step,hidden)\n",
    "                preds.append(y_hat.detach().item())\n",
    "                labs.append(y[i].detach().item())\n",
    "            trials.append(str(onehot2seq(x)))\n",
    "    df = pd.DataFrame({'trial':trials, 'label'+suffix:labs, 'pred'+suffix: preds})\n",
    "    return df \n",
    "\n",
    "\n",
    "def shuffle_weights(model):\n",
    "    model2 = OneStepRNN(input_size, output_size, hidden_size, num_layers)\n",
    "    mod_dict = model.state_dict()\n",
    "    shuffled_dict = {layer: shuffle_tensor(val) for layer, val in mod_dict.items()}\n",
    "    model2.load_state_dict(shuffled_dict)\n",
    "    return model2\n",
    "\n",
    "def shuffle_tensor(t):\n",
    "    idx = torch.randperm(t.nelement())\n",
    "    t = t.view(-1)[idx].view(t.size())\n",
    "    return t\n",
    "\n",
    "def run_sim(train_trials, test_trials):\n",
    "    model = OneStepRNN(input_size, output_size, hidden_size, num_layers)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learningRate)\n",
    "    loss1, acc1 = run_acc(model,optimizer,criterion, train_trials, test_trials, epochs)\n",
    "    return loss1, acc1, model\n",
    "\n",
    "def run_sims(i, train_trials, test_trials):\n",
    "    print('########## rep', i, '#########')\n",
    "    model = OneStepRNN(input_size, output_size, hidden_size, num_layers)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learningRate)\n",
    "    loss1, acc1 = run_acc(model,optimizer,criterion, train_trials[0], test_trials, epochs)\n",
    "    loss2, acc2 = run_acc(model,optimizer,criterion, train_trials[1], test_trials, epochs)\n",
    "    losses = np.vstack([loss1,loss2])\n",
    "    accs = np.vstack([acc1,acc2])\n",
    "    return losses, accs, model\n",
    "\n",
    "\n",
    "def seq_acc(model, testdata, hidden_size, rep = 10, verbose = False):\n",
    "\n",
    "    model.eval()\n",
    "    trials = []\n",
    "    accs = []\n",
    "    for j, (x,y) in enumerate(testdata):\n",
    "        for i in range(len(x)):\n",
    "            hidden = torch.zeros(1, hidden_size)[0]\n",
    "            for step in x[i]:\n",
    "                hidden, y_hat = model.get_activations(step,hidden)\n",
    "            correct = sum(torch.round(y[i]) == torch.round(y_hat)).item() \n",
    "            accs.append(float(correct))\n",
    "            curr_trial = onehot2seq(x)\n",
    "            trials.append(curr_trial)\n",
    "    df = pd.DataFrame({'trial':trials, 'acc':accs})\n",
    "    df['trial'] = df['trial'].apply(str)\n",
    "           \n",
    "    return df.sort_values(by = 'acc',ascending = False)\n",
    "\n",
    "def change_padder(seqs, cue_dict, xval):\n",
    "    \"\"\" changes value of X from zero to a new value\n",
    "        and recalculates sequence output\"\"\"\n",
    "    cue_dict['X'] = xval\n",
    "    inps = [s[:-1] for s in seqs]\n",
    "    for inp in inps:\n",
    "        inp.append(calculate_output(inp, cue_dict, bidmas = False))\n",
    "\n",
    "    return inps, cue_dict\n",
    "\n",
    "\n",
    "# ----------\n",
    "# plotting\n",
    "# ----------\n",
    "\n",
    "def plotNNs(loss_arrays, acc_arrays, labels, colors, title, shift = 0):\n",
    "\n",
    "    fig, axs = plt.subplots(2, 1)\n",
    "    loss_cols = ['blue', 'darkblue']\n",
    "    loss_labs = ['loss_with_primitive', 'loss_without_primitive']\n",
    "    for i, arr in enumerate(loss_arrays):\n",
    "        x = np.arange(0,arr.shape[0],1) + shift\n",
    "        mn = arr.mean(axis=1)\n",
    "        errs = arr.std(axis=1)\n",
    "        \n",
    "        axs[0].plot(x, mn, label = loss_labs[i], color = loss_cols[i])\n",
    "        axs[0].fill_between(x, mn - errs, mn + errs, alpha = 0.3, facecolor = loss_cols[i])\n",
    "    \n",
    "    axs[0].set_xlabel('epoch')\n",
    "    axs[0].set_ylabel('loss')\n",
    "    axs[0].legend()\n",
    "    \n",
    "    for i, arr in enumerate(acc_arrays):\n",
    "        x = np.arange(0,arr.shape[0],1) + shift\n",
    "        mn = arr.mean(axis=1)\n",
    "        errs = arr.std(axis=1)\n",
    "        \n",
    "        axs[1].plot(x, mn, label = labels[i], color = colors[i])\n",
    "        axs[1].fill_between(x, mn - errs, mn + errs, alpha = 0.3, facecolor = colors[i])\n",
    "    \n",
    "    axs[1].set_xlabel('epoch')\n",
    "    axs[1].set_ylabel('accuracy')\n",
    "    axs[1].legend()\n",
    "\n",
    "    fig.suptitle(title, fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5ffd051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "\n",
    "num_classes = 22\n",
    "batchsize=1\n",
    "# specs\n",
    "input_size = num_classes\n",
    "output_size = 1\n",
    "num_layers = 1\n",
    "hidden_size = 20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69bacdb",
   "metadata": {},
   "source": [
    "# Trigrams: Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9cc8d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exp1(trainseqs, testseqs):\n",
    "\n",
    "    # load data for primitive training\n",
    "    train_inputs = convert_seq2inputs(trainseqs, num_classes=num_classes, seq_len=5)\n",
    "    trainset = DataLoader(train_inputs, batch_size=batchsize, shuffle=True)\n",
    "\n",
    "    test_inputs = convert_seq2inputs(testseqs, num_classes=num_classes, seq_len=5)\n",
    "    testset = DataLoader(test_inputs, batch_size=batchsize, shuffle=True)\n",
    "\n",
    "    # run primitive training RNN\n",
    "    model = OneStepRNN(input_size, output_size, hidden_size, num_layers)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learningRate)\n",
    "    loss1, acc1 = run_acc(model,optimizer,criterion, trainset, [trainset, testset], epochs)\n",
    "\n",
    "    return {'loss':loss1, 'acc':acc1, 'mod': model, 'test': testset}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28164a46",
   "metadata": {},
   "source": [
    "## Exp 1\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e56500e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "\n",
    "num_classes = 22\n",
    "batchsize=1\n",
    "# specs\n",
    "input_size = num_classes\n",
    "output_size = 1\n",
    "num_layers = 1\n",
    "hidden_size = 20\n",
    "learningRate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bac7d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 3}\n"
     ]
    }
   ],
   "source": [
    "num_inputs = 1\n",
    "\n",
    "total_syms = ['A','B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P']\n",
    "all_syms = total_syms[:num_inputs]\n",
    "all_input_vals = list(np.arange(2,18))\n",
    "input_vals = random.sample(all_input_vals,num_inputs)\n",
    "# randomly select values for each input\n",
    "cue_dict = {}\n",
    "for i, s in enumerate(all_syms):\n",
    "    cue_dict[s] = input_vals[i]\n",
    "    \n",
    "print(cue_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335e8907",
   "metadata": {},
   "source": [
    "# Sequences + Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd7373a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_add = generate_sequences(['+'], all_syms, len_seq = 2, cue_dict = cue_dict, init_values = all_syms)\n",
    "seqs_sub = generate_sequences(['-'], all_syms, len_seq = 2, cue_dict = cue_dict, init_values = all_syms)\n",
    "seqs_both = generate_sequences(['-','+'], all_syms, len_seq = 2, cue_dict = cue_dict, init_values = all_syms)\n",
    "    \n",
    "trainseqs = seqs_add + seqs_sub\n",
    "testseqs = seqs_both.copy()\n",
    "for val in trainseqs:\n",
    "    testseqs.remove(val)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f108342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 6000\n",
    "num_sims = 8\n",
    "\n",
    "t1 = time.time()\n",
    "res  = Parallel(n_jobs = -1)(delayed(run_exp1)(trainseqs, testseqs) for i in range(num_sims))\n",
    "t2 = time.time()\n",
    "print('time: ', (t2-t1)/60)\n",
    "\n",
    "losses = np.hstack([r['loss'] for r in res])\n",
    "acc_train = np.array([r['acc'][:,0] for r in res]).T\n",
    "acc_test = np.array([r['acc'][:,1] for r in res]).T\n",
    "mods = [r['mod'] for r in res]\n",
    "tests = [r['test'] for r in res]\n",
    "\n",
    "plotNNs([losses], [acc_train, acc_test], \\\n",
    "        ['train', 'test'], colors = ['green', 'orange'], title = 'w/ prim num_inputs_'+str(7), shift = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b6fa70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
